{
  "sections": [
    {
      "is_relevant": true,
      "section_name": "Model Details: Person or organization developing model",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Model Details: Model date",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Model Details: Model version",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Model Details: Model type",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": false,
      "section_name": "Model Details: Training details",
      "irrelevant_information": "The sentence 'The spectrogram input uses 128 Mel frequency bins instead of 80 and a new language token for Cantonese are used in large-v3.' describes model features/configuration rather than the training process or methodologies."
    },
    {
      "is_relevant": true,
      "section_name": "Model Details: Paper or other resource for more information",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Model Details: Citation details",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Model Details: License",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Model Details: Contact",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Intended Use: Primary intended uses",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Intended Use: Primary intended users",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Intended Use: Out-of-scope uses",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "How to Use",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Factors: Relevant factors",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Factors: Evaluation factors",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": false,
      "section_name": "Metrics: Model performance measures",
      "irrelevant_information": "The content provides a high-level summary of performance results (e.g., '10% to 20% reduction of errors', 'Accuracy... is near state-of-the-art') rather than discussing the specific metrics used (e.g., Word Error Rate) and justifying their selection, as requested by the description."
    },
    {
      "is_relevant": true,
      "section_name": "Metrics: Decision thresholds",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Metrics: Variation approaches",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": false,
      "section_name": "Evaluation Data: Datasets",
      "irrelevant_information": "The content describes the model's performance and generalization capabilities ('Whisper demonstrates a strong ability to generalise...', 'The large-v3 model shows improved performance...') instead of providing details about the specific datasets used for evaluation (e.g., names, size, diversity, source)."
    },
    {
      "is_relevant": false,
      "section_name": "Evaluation Data: Motivation",
      "irrelevant_information": "The content describes a model characteristic ('Whisper demonstrates a strong ability to generalise...') rather than explaining the motivation for choosing specific (unlisted) evaluation datasets."
    },
    {
      "is_relevant": true,
      "section_name": "Evaluation Data: Preprocessing",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Training Data: Datasets",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Training Data: Motivation",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Training Data: Preprocessing",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Quantitative Analyses: Unitary results",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Quantitative Analyses: Intersectional results",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Memory or Hardware Requirements: Loading Requirements",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Memory or Hardware Requirements: Deploying Requirements",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Memory or Hardware Requirements: Training or Fine-tuning Requirements",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Ethical Considerations",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Caveats and Recommendations: Caveats",
      "irrelevant_information": "None"
    },
    {
      "is_relevant": true,
      "section_name": "Caveats and Recommendations: Recommendations",
      "irrelevant_information": "None"
    }
  ]
}